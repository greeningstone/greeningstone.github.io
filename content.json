{"pages":[],"posts":[{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2020/08/28/hello-world/"},{"title":"temp crawling","text":"1234# matplotlib 한글 출력 가능하도록 만들기from matplotlib import font_manager, rcfont_name = font_manager.FontProperties(fname=&quot;c:/Windows/Fonts/malgun.ttf&quot;).get_name()rc('font', family=font_name) 1234# 데이터 크롤링 모듈from selenium import webdriverfrom bs4 import BeautifulSoupimport re 1234567# 데이터 분석 모듈import pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn as snsimport timefrom datetime import datetime 12submission = pd.read_csv(&quot;C:/Users/asia_21/Desktop/kbo/submission.csv&quot;)reg = pd.read_csv(&quot;C:/Users/asia_21/Desktop/kbo/Regular_Season_Batter.csv&quot;) 1driver= webdriver.Chrome() 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# 크롤링for i in range(86): # 1982년 부터 2018년 까지 statiz에 기록된 선수들 필터링 (총 8558명) url = 'http://www.statiz.co.kr/stat.php?mid=stat&amp;re=0&amp;ys=1982&amp;ye=2018&amp;sn=100&amp;pa={}'.format(i*100) driver.get(url) driver.implicitly_wait(5) html = driver.find_element_by_xpath('//*[@id=&quot;mytable&quot;]/tbody').get_attribute(&quot;innerHTML&quot;) #기록 table을 str형태로 저장 soup = BeautifulSoup(html, 'html.parser') #str 객체를 BeautifulSoup 객체로 변경 temp = [i.text.strip() for i in soup.findAll(&quot;tr&quot;)] #tr 태그에서, text만 저장하기 temp = pd.Series(temp) #list 객체에서 series 객체로 변경 #'순'이나 'W'로 시작하는 row 제거 # 즉, 선수별 기록만 남기고, index를 reset 해주기 temp = temp[~temp.str.match(&quot;[순W]&quot;)].reset_index(drop=True) temp = temp.apply(lambda x: pd.Series(x.split(' '))) #띄어쓰기 기준으로 나눠서 dataframe으로 변경 #선수 팀 정보 이후 첫번째 기록과는 space 하나로 구분, 그 이후로는 space 두개로 구분이 되어 있음 #그래서 space 하나로 구분을 시키면, 빈 column들이 존재 하는데, 해당 column들 제거 temp = temp.replace('', np.nan).dropna(axis=1) #WAR 정보가 들어간 column이 2개 있다. (index가 1인 column과, 제일 마지막 column) #그 중에서 index가 1인 columm 제거 temp = temp.drop(1, axis=1) #선수 이름 앞의 숫자 제거 temp[0] = temp[0].str.replace(&quot;^\\d+&quot;, '') # 선수들의 생일 정보가 담긴 tag들 가지고 오기 birth = [i.find(&quot;a&quot;) for i in soup.findAll('tr') if 'birth' in i.find('a').attrs['href']] # tag내에서, 생일 날짜만 추출하기 p = re.compile(&quot;\\d{4}\\-\\d{2}\\-\\d{2}&quot;) birth = [p.findall(i.attrs['href'])[0] for i in birth] # 생일 column 추가 temp['생일'] = birth # page별 완성된 dataframe을 계속해서 result에 추가 시켜주기 if i == 0: result = temp else: result = result.append(temp) result = result.reset_index(drop=True) print(i, &quot;완료&quot;) #column 명 정보 저장 columns = ['선수'] + [i.text for i in soup.findAll(&quot;tr&quot;)[0].findAll(&quot;th&quot;)][4:-3] + ['타율', '출루', '장타', 'OPS', 'wOBA', 'wRC+', 'WAR+', '생일']#column 명 추가result.columns = columns#webdriver 종료driver.close() 0 완료 --------------------------------------------------------------------------- KeyError Traceback (most recent call last) &lt;ipython-input-52-37600f2ae032&gt; in &lt;module&gt; 26 #WAR 정보가 들어간 column이 2개 있다. (index가 1인 column과, 제일 마지막 column) 27 #그 중에서 index가 1인 columm 제거 ---&gt; 28 temp = temp.drop(1, axis=1) 29 30 #선수 이름 앞의 숫자 제거 C:\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py in drop(self, labels, axis, index, columns, level, inplace, errors) 3988 weight 1.0 0.8 3989 &quot;&quot;&quot; -&gt; 3990 return super().drop( 3991 labels=labels, 3992 axis=axis, C:\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py in drop(self, labels, axis, index, columns, level, inplace, errors) 3934 for axis, labels in axes.items(): 3935 if labels is not None: -&gt; 3936 obj = obj._drop_axis(labels, axis, level=level, errors=errors) 3937 3938 if inplace: C:\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py in _drop_axis(self, labels, axis, level, errors) 3968 new_axis = axis.drop(labels, level=level, errors=errors) 3969 else: -&gt; 3970 new_axis = axis.drop(labels, errors=errors) 3971 result = self.reindex(**{axis_name: new_axis}) 3972 C:\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py in drop(self, labels, errors) 5016 if mask.any(): 5017 if errors != &quot;ignore&quot;: -&gt; 5018 raise KeyError(f&quot;{labels[mask]} not found in axis&quot;) 5019 indexer = indexer[~mask] 5020 return self.delete(indexer) KeyError: '[1] not found in axis' 1result.shape 1result.to_csv(&quot;C:/Users/asia_21/Desktop/machine_ learning/statiz_origin.csv&quot;)","link":"/2020/08/28/temp/"}],"tags":[],"categories":[]}